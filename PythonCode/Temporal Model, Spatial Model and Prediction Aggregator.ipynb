{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, MultiTaskLassoCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aqi = pd.read_csv('/Users/nikmag/Desktop/USC/Research/SSI/processed_files/processed_los_angeles_aqi_14_months.csv')\n",
    "df_aqi.index = df_aqi['timestamp'].apply(pd.Timestamp)\n",
    "del df_aqi['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meo = pd.read_csv('/Users/nikmag/Desktop/USC/Research/SSI/processed_files/processed_los_angeles_weather_14_months.csv')\n",
    "df_meo.index = df_meo['timestamp'].apply(pd.Timestamp)\n",
    "del df_meo['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = ['W San Gabriel Vly',\n",
    " 'San Gabriel Mts',\n",
    " 'SW San Bernardino',\n",
    " 'Southeast LA CO',\n",
    " 'South Coastal LA',\n",
    " 'Central LA CO',\n",
    " 'Santa Clarita Vly',\n",
    " 'W San Fernando Vly',\n",
    " 'E San Gabriel V-2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_cols = [col for col in df_aqi.columns if col.endswith(('Antelope Vly','SW Coastal LA','NW Coastal LA','E San Fernando Vly'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meo_cols = [col for col in df_meo.columns if col.endswith(('Antelope Vly','SW Coastal LA','NW Coastal LA','E San Fernando Vly'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aqi.drop(columns=aqi_cols,axis=1,inplace=True)\n",
    "df_meo.drop(columns=meo_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_aqi,df_meo,how='left',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(0.0,np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_tf(preds, labels, null_val=np.nan):\n",
    "    \"\"\"\n",
    "    Accuracy with masking.\n",
    "    :param preds:\n",
    "    :param labels:\n",
    "    :param null_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if np.isnan(null_val):\n",
    "        mask = ~tf.is_nan(labels)\n",
    "    else:\n",
    "        mask = tf.not_equal(labels, null_val)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    mask = tf.where(tf.is_nan(mask), tf.zeros_like(mask), mask)\n",
    "    loss = tf.square(tf.subtract(preds, labels))\n",
    "    loss = loss * mask\n",
    "    loss = tf.where(tf.is_nan(loss), tf.zeros_like(loss), loss)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def masked_mae_tf(preds, labels, null_val=np.nan):\n",
    "    \"\"\"\n",
    "    Accuracy with masking.\n",
    "    :param preds:\n",
    "    :param labels:\n",
    "    :param null_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if np.isnan(null_val):\n",
    "        mask = ~tf.is_nan(labels)\n",
    "    else:\n",
    "        mask = tf.not_equal(labels, null_val)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    mask = tf.where(tf.is_nan(mask), tf.zeros_like(mask), mask)\n",
    "    loss = tf.abs(tf.subtract(preds, labels))\n",
    "    loss = loss * mask\n",
    "    loss = tf.where(tf.is_nan(loss), tf.zeros_like(loss), loss)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def masked_rmse_tf(preds, labels, null_val=np.nan):\n",
    "    \"\"\"\n",
    "    Accuracy with masking.\n",
    "    :param preds:\n",
    "    :param labels:\n",
    "    :param null_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return tf.sqrt(masked_mse_tf(preds=preds, labels=labels, null_val=null_val))\n",
    "\n",
    "\n",
    "def masked_rmse_np(preds, labels, null_val=np.nan):\n",
    "    return np.sqrt(masked_mse_np(preds=preds, labels=labels, null_val=null_val))\n",
    "\n",
    "\n",
    "def masked_mse_np(preds, labels, null_val=np.nan):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        if np.isnan(null_val):\n",
    "            mask = ~np.isnan(labels)\n",
    "        else:\n",
    "            mask = np.not_equal(labels, null_val)\n",
    "        mask = mask.astype('float32')\n",
    "        mask /= np.mean(mask)\n",
    "        rmse = np.square(np.subtract(preds, labels)).astype('float32')\n",
    "        rmse = np.nan_to_num(rmse * mask)\n",
    "        return np.mean(rmse)\n",
    "\n",
    "\n",
    "def masked_mae_np(preds, labels, null_val=np.nan):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        if np.isnan(null_val):\n",
    "            mask = ~np.isnan(labels)\n",
    "        else:\n",
    "            mask = np.not_equal(labels, null_val)\n",
    "        mask = mask.astype('float32')\n",
    "        mask /= np.mean(mask)\n",
    "        mae = np.abs(np.subtract(preds, labels)).astype('float32')\n",
    "        mae = np.nan_to_num(mae * mask)\n",
    "        return np.mean(mae)\n",
    "\n",
    "\n",
    "def masked_mape_np(preds, labels, null_val=np.nan):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        if np.isnan(null_val):\n",
    "            mask = ~np.isnan(labels)\n",
    "        else:\n",
    "            mask = np.not_equal(labels, null_val)\n",
    "        mask = mask.astype('float32')\n",
    "        mask /= np.mean(mask)\n",
    "        mape = np.abs(np.divide(np.subtract(preds, labels).astype('float32'), labels))\n",
    "        mape = np.nan_to_num(mask * mape)\n",
    "        return np.mean(mape)\n",
    "\n",
    "\n",
    "# Builds loss function.\n",
    "def masked_mse_loss(scaler, null_val):\n",
    "    def loss(preds, labels):\n",
    "        if scaler:\n",
    "            preds = scaler.inverse_transform(preds)\n",
    "            labels = scaler.inverse_transform(labels)\n",
    "        return masked_mse_tf(preds=preds, labels=labels, null_val=null_val)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_rmse_loss(scaler, null_val):\n",
    "    def loss(preds, labels):\n",
    "        if scaler:\n",
    "            preds = scaler.inverse_transform(preds)\n",
    "            labels = scaler.inverse_transform(labels)\n",
    "        return masked_rmse_tf(preds=preds, labels=labels, null_val=null_val)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_mae_loss(scaler, null_val):\n",
    "    def loss(preds, labels):\n",
    "        if scaler:\n",
    "            preds = scaler.inverse_transform(preds)\n",
    "            labels = scaler.inverse_transform(labels)\n",
    "        mae = masked_mae_tf(preds=preds, labels=labels, null_val=null_val)\n",
    "        return mae\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calculate_metrics(df_pred, df_test, null_val):\n",
    "    \"\"\"\n",
    "    Calculate the MAE, MAPE, RMSE\n",
    "    :param df_pred:\n",
    "    :param df_test:\n",
    "    :param null_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mape = masked_mape_np(preds=df_pred.as_matrix(), labels=df_test.as_matrix(), null_val=null_val)\n",
    "    mae = masked_mae_np(preds=df_pred.as_matrix(), labels=df_test.as_matrix(), null_val=null_val)\n",
    "    rmse = masked_rmse_np(preds=df_pred.as_matrix(), labels=df_test.as_matrix(), null_val=null_val)\n",
    "    return [mae, mape, rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann = {k:[] for k in range(1,13)}\n",
    "gt = {k:[] for k in range(1,13)}\n",
    "\n",
    "for sensor in sensors:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #current AQI and Weather data\n",
    "    df_temp = df.loc[:,[i for i in df.columns.tolist()]]\n",
    "    \n",
    "    #next 48 hour prediction\n",
    "    for j in range(1,49):\n",
    "        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]\n",
    "        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)\n",
    "        \n",
    "    df_temp['hz7_12_min'] = df_temp[['hz{}'.format(i) for i in range(7,13)]].min(1)\n",
    "    df_temp['hz7_12_max'] = df_temp[['hz{}'.format(i) for i in range(7,13)]].max(1)\n",
    "    \n",
    "    df_temp['hz13_24_min'] = df_temp[['hz{}'.format(i) for i in range(13,25)]].min(1)\n",
    "    df_temp['hz13_24_max'] = df_temp[['hz{}'.format(i) for i in range(13,25)]].max(1)\n",
    "    \n",
    "    df_temp['hz25_48_min'] = df_temp[['hz{}'.format(i) for i in range(25,49)]].min(1)\n",
    "    df_temp['hz25_48_max'] = df_temp[['hz{}'.format(i) for i in range(25,49)]].max(1)\n",
    "    \n",
    "    df_temp.drop(columns=['hz{}'.format(i) for i in range(7,49)],axis=1,inplace=True)\n",
    "    \n",
    "    df_temp.drop(columns=[col for col in df_temp if col.endswith(sensor)],axis=1,inplace=True)\n",
    "    \n",
    "    #past 12 hours AQI data\n",
    "    sensors1 = [s for s in sensors if s!= sensor]\n",
    "    for k in sensors1:\n",
    "        for col in ['aqi']: \n",
    "            for j in range(1,13):\n",
    "                df_temp['p{}_{}_{}'.format(j,k,col)] = df_temp[col + '_%s' % k]\n",
    "                df_temp['p{}_{}_{}'.format(j,k,col)] = df_temp['p{}_{}_{}'.format(j,k,col)].shift(j)\n",
    "    \n",
    "    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]\n",
    "    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]\n",
    "    \n",
    "    X = df_temp.loc[:,x_cols]    \n",
    "    y = df_temp.loc[:,y_cols]\n",
    "    \n",
    "    X_train = X.loc[:pd.Timestamp('2017-10-30 23:00:00'),:]\n",
    "    y_train = y.loc[:pd.Timestamp('2017-10-30 23:00:00'),:]\n",
    "    X_test = X.loc[pd.Timestamp('2017-11-01 00:00:00'):pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    y_test = y.loc[pd.Timestamp('2017-11-01 00:00:00'):pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    \n",
    "    train = pd.concat([X_train,y_train],axis=1)\n",
    "    train.dropna(axis=0,how='any',inplace=True)\n",
    "    X_train = train.loc[:,x_cols]\n",
    "    y_train = train.loc[:,y_cols]\n",
    "    \n",
    "    X_test.fillna(X_test.mean(),inplace=True)\n",
    "\n",
    "    model = MLPRegressor(hidden_layer_sizes=(100),max_iter=250,learning_rate='adaptive')\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    actual = np.array(y_test)\n",
    "    \n",
    "    j=0\n",
    "    for i in range(1,13):\n",
    "        pred_ann[i].append(predictions[:,j].tolist())\n",
    "        gt[i].append(actual[:,j].tolist())\n",
    "        j = j + 1\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    print(sensor+'='+str(np.round(end-start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = {k:[] for k in range(1,13)}\n",
    "#gt = {k:[] for k in range(1,13)}\n",
    "\n",
    "for sensor in sensors:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #current AQI\n",
    "    df_temp = df.loc[:,[i for i in df.columns.tolist() if i.endswith(sensor)]]\n",
    "    \n",
    "    #past 12 hours data\n",
    "    for col in ['aqi','pressure','wind_speed','cloud_cover','visibility','wind_bearing','humidity','temperature']: \n",
    "        for j in range(1,13):\n",
    "            df_temp['p{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]\n",
    "            df_temp['p{}_{}'.format(j,col)] = df_temp['p{}_{}'.format(j,col)].shift(j)\n",
    "    \n",
    "    #weather forecast for 48 hours\n",
    "    for col in ['pressure','wind_speed','cloud_cover','visibility','wind_bearing','humidity','temperature']:\n",
    "        for j in range(1,49):\n",
    "            df_temp['f{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]\n",
    "            df_temp['f{}_{}'.format(j,col)] = df_temp['f{}_{}'.format(j,col)].shift(-j)\n",
    "\n",
    "        df_temp['f7_12_min_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(7,13)]].min(1)\n",
    "        df_temp['f7_12_max_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(7,13)]].max(1)\n",
    "        df_temp['f13_24_min_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(13,25)]].min(1)\n",
    "        df_temp['f13_24_max_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(13,25)]].max(1)\n",
    "        df_temp['f25_48_min_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(25,49)]].min(1)\n",
    "        df_temp['f25_48_max_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(25,49)]].max(1)\n",
    "        \n",
    "        df_temp.drop(columns=['f{}_{}'.format(k,col) for k in range(7,49)],axis=1,inplace=True)\n",
    "        \n",
    "    #HourOfDay and DayOfWeek\n",
    "    df_temp['hourofday'] = df_temp.index.hour\n",
    "    df_temp['dayofweek'] = df_temp.index.dayofweek\n",
    "    df_temp['hourofday'] = df_temp['hourofday'].apply(str)\n",
    "    df_temp['dayofweek'] = df_temp['dayofweek'].apply(str)\n",
    "    \n",
    "    #next 48 hour prediction\n",
    "    for j in range(1,49):\n",
    "        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]\n",
    "        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)\n",
    "        \n",
    "    df_temp['hz7_12_min'] = df_temp[['hz{}'.format(i) for i in range(7,13)]].min(1)\n",
    "    df_temp['hz7_12_max'] = df_temp[['hz{}'.format(i) for i in range(7,13)]].max(1)\n",
    "    \n",
    "    df_temp['hz13_24_min'] = df_temp[['hz{}'.format(i) for i in range(13,25)]].min(1)\n",
    "    df_temp['hz13_24_max'] = df_temp[['hz{}'.format(i) for i in range(13,25)]].max(1)\n",
    "    \n",
    "    df_temp['hz25_48_min'] = df_temp[['hz{}'.format(i) for i in range(25,49)]].min(1)\n",
    "    df_temp['hz25_48_max'] = df_temp[['hz{}'.format(i) for i in range(25,49)]].max(1)\n",
    "    \n",
    "    df_temp.drop(columns=['hz{}'.format(i) for i in range(7,49)],axis=1,inplace=True)\n",
    "    \n",
    "    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]\n",
    "    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]\n",
    "    \n",
    "    X = df_temp.loc[:,x_cols]    \n",
    "    y = df_temp.loc[:,y_cols]\n",
    "    \n",
    "    X_train = X.loc[:pd.Timestamp('2017-10-30 23:00:00'),:]\n",
    "    y_train = y.loc[:pd.Timestamp('2017-10-30 23:00:00'),:]\n",
    "    X_test = X.loc[pd.Timestamp('2017-11-01 00:00:00'):pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    y_test = y.loc[pd.Timestamp('2017-11-01 00:00:00'):pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    \n",
    "    train = pd.concat([X_train,y_train],axis=1)\n",
    "    train.dropna(axis=0,how='any',inplace=True)\n",
    "    X_train = train.loc[:,x_cols]\n",
    "    y_train = train.loc[:,y_cols]\n",
    "    \n",
    "    X_test.fillna(X_test.mean(),inplace=True)\n",
    "\n",
    "    model = MultiTaskLassoCV(alphas=[0.1,1,10],cv=3)\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    actual = np.array(y_test)\n",
    "    \n",
    "    j=0\n",
    "    for i in range(1,13):\n",
    "        pred_lr[i].append(predictions[:,j].tolist())\n",
    "        #gt[i].append(actual[:,j].tolist())\n",
    "        j = j + 1\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    print(sensor+'='+str(np.round(end-start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = pd.DataFrame()\n",
    "for h in range(1,13):\n",
    "    df_gt = pd.concat([df_gt,pd.DataFrame(np.array(gt[h]).T)\\\n",
    "              .rename(columns = {i: \"{}_\".format(h) + sensor for i,sensor in enumerate(sensors)})],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ann = pd.DataFrame()\n",
    "for h in range(1,13):\n",
    "    df_ann = pd.concat([df_ann,pd.DataFrame(np.array(pred_ann[h]).T)\\\n",
    "               .rename(columns = {i: \"{}_\".format(h) + sensor for i,sensor in enumerate(sensors)})],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = pd.DataFrame()\n",
    "for h in range(1,13):\n",
    "    df_lr = pd.concat([df_lr,pd.DataFrame(np.array(pred_lr[h]).T)\\\n",
    "              .rename(columns = {i: \"{}_\".format(h) + sensor for i,sensor in enumerate(sensors)})],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_gt.columns.tolist():\n",
    "    X_train = pd.concat([df_ann[col],df_lr[col]],axis=1)\n",
    "    y_train = df_gt[col]\n",
    "    X_test = pd.concat([df_test_ann[col],df_test_lr[col]],axis=1)\n",
    "    \n",
    "    X_test.fillna(X_test.mean(),inplace=True)\n",
    "    \n",
    "    train = pd.concat([X_train,y_train],axis=1)\n",
    "    train.dropna(axis=0,how='any',inplace=True)\n",
    "    X_train = train.iloc[:,[0,1]]\n",
    "    y_train = train.iloc[:,2]\n",
    "    \n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    df_test_pred[col] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    cols = [col for col in df_test_pred.columns.tolist() if col.startswith(str(i)+\"_\")]\n",
    "    res = calculate_metrics(df_test_pred[cols],df_test_gt[cols],np.nan)\n",
    "    print(res[0])\n",
    "    print(res[2])\n",
    "    print(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
