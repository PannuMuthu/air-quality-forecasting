{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, MultiTaskLassoCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aqi = pd.read_csv('/Users/nikmag/Desktop/USC/Research/SSI/processed_files/processed_los_angeles_aqi_14_months.csv')\n",
    "df_aqi.index = df_aqi['timestamp'].apply(pd.Timestamp)\n",
    "del df_aqi['timestamp']\n",
    "#df_aqi = df_aqi.loc[:,[i for i in df_aqi.columns.tolist() if i.startswith('aqi')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meo = pd.read_csv('/Users/nikmag/Desktop/USC/Research/SSI/processed_files/processed_los_angeles_weather_14_months.csv')\n",
    "df_meo.index = df_meo['timestamp'].apply(pd.Timestamp)\n",
    "del df_meo['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = ['W San Gabriel Vly',\n",
    " 'San Gabriel Mts',\n",
    " 'SW San Bernardino',\n",
    " 'Southeast LA CO',\n",
    " 'South Coastal LA',\n",
    " 'Central LA CO',\n",
    " 'Santa Clarita Vly',\n",
    " 'W San Fernando Vly',\n",
    " 'E San Gabriel V-2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_cols = [col for col in df_aqi.columns if col.endswith(('Antelope Vly','SW Coastal LA','NW Coastal LA','E San Fernando Vly'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meo_cols = [col for col in df_meo.columns if col.endswith(('Antelope Vly','SW Coastal LA','NW Coastal LA','E San Fernando Vly'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aqi.drop(columns=aqi_cols,axis=1,inplace=True)\n",
    "df_meo.drop(columns=meo_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_aqi,df_meo,how='left',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(0.0,np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_tf(preds, labels, null_val=np.nan):\n",
    "    \"\"\"\n",
    "    Accuracy with masking.\n",
    "    :param preds:\n",
    "    :param labels:\n",
    "    :param null_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if np.isnan(null_val):\n",
    "        mask = ~tf.is_nan(labels)\n",
    "    else:\n",
    "        mask = tf.not_equal(labels, null_val)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    mask = tf.where(tf.is_nan(mask), tf.zeros_like(mask), mask)\n",
    "    loss = tf.square(tf.subtract(preds, labels))\n",
    "    loss = loss * mask\n",
    "    loss = tf.where(tf.is_nan(loss), tf.zeros_like(loss), loss)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def masked_mae_tf(preds, labels, null_val=np.nan):\n",
    "    \"\"\"\n",
    "    Accuracy with masking.\n",
    "    :param preds:\n",
    "    :param labels:\n",
    "    :param null_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if np.isnan(null_val):\n",
    "        mask = ~tf.is_nan(labels)\n",
    "    else:\n",
    "        mask = tf.not_equal(labels, null_val)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    mask = tf.where(tf.is_nan(mask), tf.zeros_like(mask), mask)\n",
    "    loss = tf.abs(tf.subtract(preds, labels))\n",
    "    loss = loss * mask\n",
    "    loss = tf.where(tf.is_nan(loss), tf.zeros_like(loss), loss)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def masked_rmse_tf(preds, labels, null_val=np.nan):\n",
    "    \"\"\"\n",
    "    Accuracy with masking.\n",
    "    :param preds:\n",
    "    :param labels:\n",
    "    :param null_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return tf.sqrt(masked_mse_tf(preds=preds, labels=labels, null_val=null_val))\n",
    "\n",
    "\n",
    "def masked_rmse_np(preds, labels, null_val=np.nan):\n",
    "    return np.sqrt(masked_mse_np(preds=preds, labels=labels, null_val=null_val))\n",
    "\n",
    "\n",
    "def masked_mse_np(preds, labels, null_val=np.nan):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        if np.isnan(null_val):\n",
    "            mask = ~np.isnan(labels)\n",
    "        else:\n",
    "            mask = np.not_equal(labels, null_val)\n",
    "        mask = mask.astype('float32')\n",
    "        mask /= np.mean(mask)\n",
    "        rmse = np.square(np.subtract(preds, labels)).astype('float32')\n",
    "        rmse = np.nan_to_num(rmse * mask)\n",
    "        return np.mean(rmse)\n",
    "\n",
    "\n",
    "def masked_mae_np(preds, labels, null_val=np.nan):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        if np.isnan(null_val):\n",
    "            mask = ~np.isnan(labels)\n",
    "        else:\n",
    "            mask = np.not_equal(labels, null_val)\n",
    "        mask = mask.astype('float32')\n",
    "        mask /= np.mean(mask)\n",
    "        mae = np.abs(np.subtract(preds, labels)).astype('float32')\n",
    "        mae = np.nan_to_num(mae * mask)\n",
    "        return np.mean(mae)\n",
    "\n",
    "\n",
    "def masked_mape_np(preds, labels, null_val=np.nan):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        if np.isnan(null_val):\n",
    "            mask = ~np.isnan(labels)\n",
    "        else:\n",
    "            mask = np.not_equal(labels, null_val)\n",
    "        mask = mask.astype('float32')\n",
    "        mask /= np.mean(mask)\n",
    "        mape = np.abs(np.divide(np.subtract(preds, labels).astype('float32'), labels))\n",
    "        mape = np.nan_to_num(mask * mape)\n",
    "        return np.mean(mape)\n",
    "\n",
    "\n",
    "# Builds loss function.\n",
    "def masked_mse_loss(scaler, null_val):\n",
    "    def loss(preds, labels):\n",
    "        if scaler:\n",
    "            preds = scaler.inverse_transform(preds)\n",
    "            labels = scaler.inverse_transform(labels)\n",
    "        return masked_mse_tf(preds=preds, labels=labels, null_val=null_val)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_rmse_loss(scaler, null_val):\n",
    "    def loss(preds, labels):\n",
    "        if scaler:\n",
    "            preds = scaler.inverse_transform(preds)\n",
    "            labels = scaler.inverse_transform(labels)\n",
    "        return masked_rmse_tf(preds=preds, labels=labels, null_val=null_val)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_mae_loss(scaler, null_val):\n",
    "    def loss(preds, labels):\n",
    "        if scaler:\n",
    "            preds = scaler.inverse_transform(preds)\n",
    "            labels = scaler.inverse_transform(labels)\n",
    "        mae = masked_mae_tf(preds=preds, labels=labels, null_val=null_val)\n",
    "        return mae\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calculate_metrics(df_pred, df_test, null_val):\n",
    "    \"\"\"\n",
    "    Calculate the MAE, MAPE, RMSE\n",
    "    :param df_pred:\n",
    "    :param df_test:\n",
    "    :param null_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mape = masked_mape_np(preds=df_pred.as_matrix(), labels=df_test.as_matrix(), null_val=null_val)\n",
    "    mae = masked_mae_np(preds=df_pred.as_matrix(), labels=df_test.as_matrix(), null_val=null_val)\n",
    "    rmse = masked_rmse_np(preds=df_pred.as_matrix(), labels=df_test.as_matrix(), null_val=null_val)\n",
    "    return [mae, mape, rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24 Lagged Variables\n",
    "\n",
    "Input - AQI(t), AQI(t-1),..., AQI(t-24) + Weather vars (t,....,t-24)\n",
    "\n",
    "Output - AQI(t+1), AQI(t+6), AQI(t+12), AQI(t+18), AQI(t+24) (Multi-output prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikmag/anaconda2/lib/python2.7/site-packages/pandas/core/generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/nikmag/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W San Gabriel Vly=71.64\n",
      "San Gabriel Mts=94.32\n",
      "SW San Bernardino=111.7\n",
      "Southeast LA CO=111.85\n",
      "South Coastal LA=86.47\n",
      "Central LA CO=30.51\n",
      "Santa Clarita Vly=27.42\n",
      "W San Fernando Vly=30.49\n",
      "E San Gabriel V-2=29.69\n"
     ]
    }
   ],
   "source": [
    "pred = {k:[] for k in [1,6,12,18,24]}\n",
    "gt = {k:[] for k in [1,6,12,18,24]}\n",
    "\n",
    "for sensor in sensors:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    df_temp = df.loc[:,[i for i in df.columns.tolist() if i.endswith(sensor)]]\n",
    "    \n",
    "    for col in ['aqi','pressure','wind_speed','cloud_cover','visibility','wind_bearing','humidity','temperature']: \n",
    "        for j in range(1,24):\n",
    "            df_temp['p{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]\n",
    "            df_temp['p{}_{}'.format(j,col)] = df_temp['p{}_{}'.format(j,col)].shift(j)\n",
    "\n",
    "    for j in [1,6,12,18,24]:\n",
    "        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]\n",
    "        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)\n",
    "    \n",
    "    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]\n",
    "    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]\n",
    "    \n",
    "    X = df_temp.loc[:,x_cols]    \n",
    "    y = df_temp.loc[:,y_cols]\n",
    "    \n",
    "    X_train = X.loc[:pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    y_train = y.loc[:pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    X_test = X.loc[pd.Timestamp('2018-01-01 00:00:00'):,:]\n",
    "    y_test = y.loc[pd.Timestamp('2018-01-01 00:00:00'):,:]\n",
    "    \n",
    "    #nik\n",
    "    train = pd.concat([X_train,y_train],axis=1)\n",
    "    train.dropna(axis=0,how='any',inplace=True)\n",
    "    X_train = train.loc[:,x_cols]\n",
    "    y_train = train.loc[:,y_cols]\n",
    "    \n",
    "    #nik\n",
    "    X_test.fillna(X_test.mean(),inplace=True)\n",
    "\n",
    "    model = MultiTaskLassoCV(alphas=[0.1,1,10,100],cv=3)\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    actual = np.array(y_test)\n",
    "    \n",
    "    j=0\n",
    "    for i in [1,6,12,18,24]:\n",
    "        pred[i].append(predictions[:,j].tolist())\n",
    "        gt[i].append(actual[:,j].tolist())\n",
    "        j = j + 1\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    print(sensor+'='+str(np.round(end-start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.04\n",
      "8.94\n",
      "0.27\n",
      "14.33\n",
      "18.7\n",
      "0.6\n",
      "16.16\n",
      "20.83\n",
      "0.71\n",
      "17.06\n",
      "21.95\n",
      "0.77\n",
      "17.38\n",
      "22.43\n",
      "0.79\n"
     ]
    }
   ],
   "source": [
    "result_mape = {k:[] for k in [1,6,12,18,24]}\n",
    "result_mae = {k:[] for k in [1,6,12,18,24]}\n",
    "result_rmse = {k:[] for k in [1,6,12,18,24]}\n",
    "\n",
    "for i in gt.keys():\n",
    "    res = calculate_metrics(pd.DataFrame(np.array(pred[i]).T),pd.DataFrame(np.array(gt[i]).T),np.nan)\n",
    "    result_mape[i] = res[1]\n",
    "    result_mae[i]= res[0]\n",
    "    result_rmse[i]= res[2]\n",
    "\n",
    "final_dict = {k:[] for k in [1,6,12,18,24]}\n",
    "for i in [1,6,12,18,24]:\n",
    "    final_dict[i].append(np.round(result_mae[i],2))\n",
    "    final_dict[i].append(np.round(result_rmse[i],2))\n",
    "    final_dict[i].append(np.round(result_mape[i],2))\n",
    "\n",
    "for i in [1,6,12,18,24]:\n",
    "    for j in final_dict[i]:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikmag/anaconda2/lib/python2.7/site-packages/pandas/core/generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/nikmag/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W San Gabriel Vly=159.11\n",
      "San Gabriel Mts=178.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikmag/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:1778: ConvergenceWarning: Objective did not converge, you might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW San Bernardino=187.02\n",
      "Southeast LA CO=186.31\n",
      "South Coastal LA=165.83\n",
      "Central LA CO=166.8\n",
      "Santa Clarita Vly=220.22\n",
      "W San Fernando Vly=299.73\n",
      "E San Gabriel V-2=288.48\n"
     ]
    }
   ],
   "source": [
    "pred = {k:[] for k in [1,6,12,18,24]}\n",
    "gt = {k:[] for k in [1,6,12,18,24]}\n",
    "\n",
    "for sensor in sensors:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    df_temp = df.loc[:,[i for i in df.columns.tolist()]]\n",
    "    \n",
    "    for k in sensors:\n",
    "        for col in ['aqi','pressure','wind_speed','cloud_cover','visibility','wind_bearing','humidity','temperature']:\n",
    "            for j in range(1,24):\n",
    "                df_temp['p{}_{}_{}'.format(j,k,col)] = df_temp[col + '_%s' % k]\n",
    "                df_temp['p{}_{}_{}'.format(j,k,col)] = df_temp['p{}_{}_{}'.format(j,k,col)].shift(j)\n",
    "    \n",
    "    for j in [1,6,12,18,24]:\n",
    "        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]\n",
    "        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)\n",
    "    \n",
    "    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]\n",
    "    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]\n",
    "    \n",
    "    X = df_temp.loc[:,x_cols]    \n",
    "    y = df_temp.loc[:,y_cols]\n",
    "    \n",
    "    X_train = X.loc[:pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    y_train = y.loc[:pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    X_test = X.loc[pd.Timestamp('2018-01-01 00:00:00'):,:]\n",
    "    y_test = y.loc[pd.Timestamp('2018-01-01 00:00:00'):,:]\n",
    "    \n",
    "    #nik\n",
    "    train = pd.concat([X_train,y_train],axis=1)\n",
    "    train.dropna(axis=0,how='any',inplace=True)\n",
    "    X_train = train.loc[:,x_cols]\n",
    "    y_train = train.loc[:,y_cols]\n",
    "    \n",
    "    #nik\n",
    "    X_test.fillna(X_test.mean(),inplace=True)\n",
    "\n",
    "    model = MultiTaskLassoCV(alphas=[1,10,100],cv=3)\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    actual = np.array(y_test)\n",
    "    \n",
    "    j=0\n",
    "    for i in [1,6,12,18,24]:\n",
    "        pred[i].append(predictions[:,j].tolist())\n",
    "        gt[i].append(actual[:,j].tolist())\n",
    "        j = j + 1\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    print(sensor+'='+str(np.round(end-start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pred.keys():\n",
    "    pred_csv = pd.DataFrame(np.array(pred[i])).T\n",
    "    pred_csv.columns = ['pred_{}'.format(sensor) for sensor in sensors]\n",
    "    pred_csv.index = X_test.index\n",
    "    gt_csv = pd.DataFrame(np.array(gt[i])).T\n",
    "    gt_csv.columns = ['actual_{}'.format(sensor) for sensor in sensors]\n",
    "    gt_csv.index = X_test.index\n",
    "    main_csv = pd.concat([pred_csv,gt_csv],axis=1)\n",
    "    main_csv.to_csv('/Users/nikmag/Desktop/var_horizon_{}_output.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 1, 18, 12, 6]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.93\n",
      "8.72\n",
      "0.27\n",
      "13.81\n",
      "18.01\n",
      "0.58\n",
      "15.58\n",
      "20.2\n",
      "0.69\n",
      "16.83\n",
      "21.56\n",
      "0.78\n",
      "17.31\n",
      "22.23\n",
      "0.81\n"
     ]
    }
   ],
   "source": [
    "result_mape = {k:[] for k in [1,6,12,18,24]}\n",
    "result_mae = {k:[] for k in [1,6,12,18,24]}\n",
    "result_rmse = {k:[] for k in [1,6,12,18,24]}\n",
    "\n",
    "for i in gt.keys():\n",
    "    res = calculate_metrics(pd.DataFrame(np.array(pred[i]).T),pd.DataFrame(np.array(gt[i]).T),np.nan)\n",
    "    result_mape[i] = res[1]\n",
    "    result_mae[i]= res[0]\n",
    "    result_rmse[i]= res[2]\n",
    "\n",
    "final_dict = {k:[] for k in [1,6,12,18,24]}\n",
    "for i in [1,6,12,18,24]:\n",
    "    final_dict[i].append(np.round(result_mae[i],2))\n",
    "    final_dict[i].append(np.round(result_rmse[i],2))\n",
    "    final_dict[i].append(np.round(result_mape[i],2))\n",
    "\n",
    "for i in [1,6,12,18,24]:\n",
    "    for j in final_dict[i]:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W San Gabriel Vly=35.21\n",
      "San Gabriel Mts=36.75\n",
      "SW San Bernardino=34.35\n",
      "Southeast LA CO=37.18\n",
      "South Coastal LA=34.38\n",
      "Central LA CO=36.28\n",
      "Santa Clarita Vly=33.28\n",
      "W San Fernando Vly=37.75\n",
      "E San Gabriel V-2=33.91\n"
     ]
    }
   ],
   "source": [
    "result_mape = {k:[] for k in [1,6,12,18,24]}\n",
    "result_mae = {k:[] for k in [1,6,12,18,24]}\n",
    "result_rmse = {k:[] for k in [1,6,12,18,24]}\n",
    "\n",
    "for sensor in sensors:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    df_temp = df.loc[:,[i for i in df.columns.tolist() if i.endswith(sensor)]]\n",
    "    \n",
    "    for col in ['aqi','pressure','wind_speed','cloud_cover','visibility','wind_bearing','humidity','temperature']: \n",
    "        for j in range(1,24):\n",
    "            df_temp['p{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]\n",
    "            df_temp['p{}_{}'.format(j,col)] = df_temp['p{}_{}'.format(j,col)].shift(j)\n",
    "\n",
    "    for j in [1,6,12,18,24]:\n",
    "        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]\n",
    "        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)\n",
    "    \n",
    "    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]\n",
    "    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]\n",
    "    \n",
    "    X = df_temp.loc[:,x_cols]    \n",
    "    y = df_temp.loc[:,y_cols]\n",
    "    \n",
    "    X_train = X.loc[:pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    y_train = y.loc[:pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    X_test = X.loc[pd.Timestamp('2018-01-01 00:00:00'):,:]\n",
    "    y_test = y.loc[pd.Timestamp('2018-01-01 00:00:00'):,:]\n",
    "    \n",
    "    #nik\n",
    "    train = pd.concat([X_train,y_train],axis=1)\n",
    "    train.dropna(axis=0,how='any',inplace=True)\n",
    "    X_train = train.loc[:,x_cols]\n",
    "    y_train = train.loc[:,y_cols]\n",
    "    \n",
    "    #nik\n",
    "    X_test.fillna(X_test.mean(),inplace=True)\n",
    "\n",
    "    gbm = GradientBoostingRegressor(learning_rate=0.05,max_features=0.6,max_leaf_nodes=31,n_estimators=200)\n",
    "    model = MultiOutputRegressor(gbm,-1)\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    actual = np.array(y_test)\n",
    "    \n",
    "    j=0\n",
    "    for i in [1,6,12,18,24]:\n",
    "        pred[i].append(predictions[:,j].tolist())\n",
    "        gt[i].append(actual[:,j].tolist())\n",
    "        j = j + 1\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    print(sensor+'='+str(np.round(end-start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.01\n",
      "8.86\n",
      "0.28\n",
      "13.63\n",
      "17.87\n",
      "0.59\n",
      "15.68\n",
      "20.4\n",
      "0.7\n",
      "16.99\n",
      "21.91\n",
      "0.78\n",
      "17.6\n",
      "22.68\n",
      "0.81\n"
     ]
    }
   ],
   "source": [
    "result_mape = {k:[] for k in [1,6,12,18,24]}\n",
    "result_mae = {k:[] for k in [1,6,12,18,24]}\n",
    "result_rmse = {k:[] for k in [1,6,12,18,24]}\n",
    "\n",
    "for i in gt.keys():\n",
    "    res = calculate_metrics(pd.DataFrame(np.array(pred[i]).T),pd.DataFrame(np.array(gt[i]).T),np.nan)\n",
    "    result_mape[i] = res[1]\n",
    "    result_mae[i]= res[0]\n",
    "    result_rmse[i]= res[2]\n",
    "\n",
    "final_dict = {k:[] for k in [1,6,12,18,24]}\n",
    "for i in [1,6,12,18,24]:\n",
    "    final_dict[i].append(np.round(result_mae[i],2))\n",
    "    final_dict[i].append(np.round(result_rmse[i],2))\n",
    "    final_dict[i].append(np.round(result_mape[i],2))\n",
    "\n",
    "for i in [1,6,12,18,24]:\n",
    "    for j in final_dict[i]:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W San Gabriel Vly=402.59\n",
      "San Gabriel Mts=471.79\n",
      "SW San Bernardino=409.71\n",
      "Southeast LA CO=471.17\n",
      "South Coastal LA=428.93\n",
      "Central LA CO=457.54\n",
      "Santa Clarita Vly=396.01\n",
      "W San Fernando Vly=487.0\n",
      "E San Gabriel V-2=373.67\n"
     ]
    }
   ],
   "source": [
    "result_mape = {k:[] for k in [1,6,12,18,24]}\n",
    "result_mae = {k:[] for k in [1,6,12,18,24]}\n",
    "result_rmse = {k:[] for k in [1,6,12,18,24]}\n",
    "\n",
    "for sensor in sensors:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    df_temp = df.loc[:,[i for i in df.columns.tolist() if i.endswith(sensor)]]\n",
    "    \n",
    "    for col in ['aqi','pressure','wind_speed','cloud_cover','visibility','wind_bearing','humidity','temperature']: \n",
    "        for j in range(1,24):\n",
    "            df_temp['p{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]\n",
    "            df_temp['p{}_{}'.format(j,col)] = df_temp['p{}_{}'.format(j,col)].shift(j)\n",
    "\n",
    "    for j in [1,6,12,18,24]:\n",
    "        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]\n",
    "        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)\n",
    "    \n",
    "    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]\n",
    "    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]\n",
    "    \n",
    "    X = df_temp.loc[:,x_cols]    \n",
    "    y = df_temp.loc[:,y_cols]\n",
    "    \n",
    "    X_train = X.loc[:pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    y_train = y.loc[:pd.Timestamp('2017-12-31 23:00:00'),:]\n",
    "    X_test = X.loc[pd.Timestamp('2018-01-01 00:00:00'):,:]\n",
    "    y_test = y.loc[pd.Timestamp('2018-01-01 00:00:00'):,:]\n",
    "    \n",
    "    #nik\n",
    "    train = pd.concat([X_train,y_train],axis=1)\n",
    "    train.dropna(axis=0,how='any',inplace=True)\n",
    "    X_train = train.loc[:,x_cols]\n",
    "    y_train = train.loc[:,y_cols]\n",
    "    \n",
    "    #nik\n",
    "    X_test.fillna(X_test.mean(),inplace=True)\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=600)\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    actual = np.array(y_test)\n",
    "    \n",
    "    j=0\n",
    "    for i in [1,6,12,18,24]:\n",
    "        pred[i].append(predictions[:,j].tolist())\n",
    "        gt[i].append(actual[:,j].tolist())\n",
    "        j = j + 1\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    print(sensor+'='+str(np.round(end-start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.33\n",
      "9.29\n",
      "0.29\n",
      "13.86\n",
      "18.1\n",
      "0.59\n",
      "15.92\n",
      "20.66\n",
      "0.69\n",
      "17.27\n",
      "22.27\n",
      "0.77\n",
      "17.82\n",
      "23.01\n",
      "0.79\n"
     ]
    }
   ],
   "source": [
    "result_mape = {k:[] for k in [1,6,12,18,24]}\n",
    "result_mae = {k:[] for k in [1,6,12,18,24]}\n",
    "result_rmse = {k:[] for k in [1,6,12,18,24]}\n",
    "\n",
    "for i in gt.keys():\n",
    "    res = calculate_metrics(pd.DataFrame(np.array(pred[i]).T),pd.DataFrame(np.array(gt[i]).T),np.nan)\n",
    "    result_mape[i] = res[1]\n",
    "    result_mae[i]= res[0]\n",
    "    result_rmse[i]= res[2]\n",
    "\n",
    "final_dict = {k:[] for k in [1,6,12,18,24]}\n",
    "for i in [1,6,12,18,24]:\n",
    "    final_dict[i].append(np.round(result_mae[i],2))\n",
    "    final_dict[i].append(np.round(result_rmse[i],2))\n",
    "    final_dict[i].append(np.round(result_mape[i],2))\n",
    "\n",
    "for i in [1,6,12,18,24]:\n",
    "    for j in final_dict[i]:\n",
    "        print(j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
